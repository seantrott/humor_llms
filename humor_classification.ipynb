{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1d194f",
   "metadata": {},
   "source": [
    "# Does GPT-3 appreciate jokes?\n",
    "\n",
    "*Sean Trott*\n",
    "\n",
    "**Goal**: Does GPT-3 successfully distinguish jokes from non-jokes? How funny does it find jokes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3a66f",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "### Set up API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b30cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e606d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4ff30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # makes figs nicer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91fcfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in key\n",
    "with open('gpt_key', 'r') as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "org = lines[0]\n",
    "api_key = lines[1]\n",
    "openai.organization = org # org\n",
    "openai.api_key = api_key # api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ea168",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7363f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/raw/coulson_stimuli.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eab8dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Exp Code</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Correct</th>\n",
       "      <th>First Five Words</th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Same/Different</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J</td>\n",
       "      <td>1017</td>\n",
       "      <td>A committee keeps minutes and takes hours.</td>\n",
       "      <td>Committees are very efficient.</td>\n",
       "      <td>no</td>\n",
       "      <td>a committee keeps minutes and</td>\n",
       "      <td>1</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>3017</td>\n",
       "      <td>A committee keeps minutes and takes votes.</td>\n",
       "      <td>Committees keep records and make decisions.</td>\n",
       "      <td>yes</td>\n",
       "      <td>a committee keeps minutes and</td>\n",
       "      <td>1</td>\n",
       "      <td>Different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>4013</td>\n",
       "      <td>A device for finding furniture in the dark is ...</td>\n",
       "      <td>The candle gives off light.</td>\n",
       "      <td>yes</td>\n",
       "      <td>a device for finding furniture</td>\n",
       "      <td>2</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J</td>\n",
       "      <td>2013</td>\n",
       "      <td>A device for finding furniture in the dark is ...</td>\n",
       "      <td>People run into furniture when it's dark.</td>\n",
       "      <td>yes</td>\n",
       "      <td>a device for finding furniture</td>\n",
       "      <td>2</td>\n",
       "      <td>Same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>6056</td>\n",
       "      <td>A good source of vitamin A is orange vegetable...</td>\n",
       "      <td>Carrots contain vitamin A.</td>\n",
       "      <td>yes</td>\n",
       "      <td>a good source of vitamin</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  Exp Code                                           Sentence  \\\n",
       "0         J      1017         A committee keeps minutes and takes hours.   \n",
       "1         S      3017         A committee keeps minutes and takes votes.   \n",
       "2         S      4013  A device for finding furniture in the dark is ...   \n",
       "3         J      2013  A device for finding furniture in the dark is ...   \n",
       "4         E      6056  A good source of vitamin A is orange vegetable...   \n",
       "\n",
       "                                        Answer Correct  \\\n",
       "0               Committees are very efficient.      no   \n",
       "1  Committees keep records and make decisions.     yes   \n",
       "2                  The candle gives off light.     yes   \n",
       "3    People run into furniture when it's dark.     yes   \n",
       "4                   Carrots contain vitamin A.     yes   \n",
       "\n",
       "                 First Five Words  Group Number Same/Different  \n",
       "0   a committee keeps minutes and             1      Different  \n",
       "1   a committee keeps minutes and             1      Different  \n",
       "2  a device for finding furniture             2           Same  \n",
       "3  a device for finding furniture             2           Same  \n",
       "4        a good source of vitamin             3              E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f217c9",
   "metadata": {},
   "source": [
    "### Setup helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f83bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import backoff  # for exponential backoff\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_response(prompt, model, tokens = 0):\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=tokens, ### 0\n",
    "        logprobs = 0,\n",
    "        top_p=1,\n",
    "        echo = True\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ca347",
   "metadata": {},
   "source": [
    "## Pt. 1: Joke classification\n",
    "\n",
    "In this section, we ask whether GPT-3 successfully distinguishes jokes from non-jokes by comparing `p(yes)` vs. `p(no)` to the question: \"Is this statement a joke?\" for jokes and non-jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2e587d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be shown a series of statements. For each, your task is to determine whether or not the statement is a joke.\n"
     ]
    }
   ],
   "source": [
    "INSTRUCTIONS_CLASSIFICATION = \"You will be shown a series of statements. For each, your task is to determine whether or not the statement is a joke.\"\n",
    "print(INSTRUCTIONS_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d34baf",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7443bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sentence, prompt, response):\n",
    "    prompt = \"{p}\\n\\nIs this statement a joke?\\n\\n{x}\\n\\nAnswer: {y}\".format(\n",
    "        p = prompt, x = sentence, y = response)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c2c17",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1d3b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"text-davinci-002\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fed10af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [02:48<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    \n",
    "    sentence = row['Sentence']\n",
    "    answer = row['Answer']\n",
    "    \n",
    "    yes_prompt = format_prompt(sentence, prompt = INSTRUCTIONS_CLASSIFICATION, \n",
    "                               response = \"Yes\")\n",
    "    no_prompt = format_prompt(sentence, prompt = INSTRUCTIONS_CLASSIFICATION, \n",
    "                              response = \"No\")\n",
    "    \n",
    "    for model in models:\n",
    "\n",
    "        ## Get responses\n",
    "        yes_response = get_response(yes_prompt, model = model)\n",
    "        no_response = get_response(no_prompt, model = model)\n",
    "        \n",
    "        \n",
    "        ## Extract tokenized representations: YES\n",
    "        yes_tokens = yes_response.to_dict()['choices'][0]['logprobs']['tokens']\n",
    "        yes_identified_token = yes_tokens[-1]\n",
    "        if yes_identified_token != \" Yes\":\n",
    "            print(yes_identified_token) \n",
    "            \n",
    "        ## Extract tokenized representations: NO\n",
    "        no_tokens = no_response.to_dict()['choices'][0]['logprobs']['tokens']\n",
    "        no_identified_token = no_tokens[-1]\n",
    "        if no_identified_token != \" No\":\n",
    "            print(no_identified_token)\n",
    "        \n",
    "        \n",
    "        ## Get logprobs\n",
    "        lp_yes = yes_response.to_dict()['choices'][0]['logprobs']['token_logprobs'][-1]\n",
    "        lp_no = no_response.to_dict()['choices'][0]['logprobs']['token_logprobs'][-1]\n",
    "            \n",
    "        \n",
    "        results.append({\n",
    "            'model': model,\n",
    "            'sentence': sentence,\n",
    "            'answer': answer,\n",
    "            'condition': row['Condition'],\n",
    "            'correct': row['Correct'],\n",
    "            'yes_lp': lp_yes, \n",
    "            'no_lp': lp_no\n",
    "        })\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a8d68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b3be56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sentence</th>\n",
       "      <th>answer</th>\n",
       "      <th>shots</th>\n",
       "      <th>condition</th>\n",
       "      <th>correct</th>\n",
       "      <th>yes_lp</th>\n",
       "      <th>no_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A committee keeps minutes and takes hours.</td>\n",
       "      <td>Committees are very efficient.</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "      <td>no</td>\n",
       "      <td>-1.743327</td>\n",
       "      <td>-1.063580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A committee keeps minutes and takes votes.</td>\n",
       "      <td>Committees keep records and make decisions.</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>yes</td>\n",
       "      <td>-7.378091</td>\n",
       "      <td>-0.278357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A device for finding furniture in the dark is ...</td>\n",
       "      <td>The candle gives off light.</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>yes</td>\n",
       "      <td>-3.008099</td>\n",
       "      <td>-0.435998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A device for finding furniture in the dark is ...</td>\n",
       "      <td>People run into furniture when it's dark.</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "      <td>yes</td>\n",
       "      <td>-3.017649</td>\n",
       "      <td>-0.359194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A good source of vitamin A is orange vegetable...</td>\n",
       "      <td>Carrots contain vitamin A.</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>yes</td>\n",
       "      <td>-10.157684</td>\n",
       "      <td>-0.346942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model                                           sentence  \\\n",
       "0  text-davinci-002         A committee keeps minutes and takes hours.   \n",
       "1  text-davinci-002         A committee keeps minutes and takes votes.   \n",
       "2  text-davinci-002  A device for finding furniture in the dark is ...   \n",
       "3  text-davinci-002  A device for finding furniture in the dark is ...   \n",
       "4  text-davinci-002  A good source of vitamin A is orange vegetable...   \n",
       "\n",
       "                                        answer  shots condition correct  \\\n",
       "0               Committees are very efficient.      0         J      no   \n",
       "1  Committees keep records and make decisions.      0         S     yes   \n",
       "2                  The candle gives off light.      0         S     yes   \n",
       "3    People run into furniture when it's dark.      0         J     yes   \n",
       "4                   Carrots contain vitamin A.      0         E     yes   \n",
       "\n",
       "      yes_lp     no_lp  \n",
       "0  -1.743327 -1.063580  \n",
       "1  -7.378091 -0.278357  \n",
       "2  -3.008099 -0.435998  \n",
       "3  -3.017649 -0.359194  \n",
       "4 -10.157684 -0.346942  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02f979b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['lp_ratio'] = df_results['yes_lp'] - df_results['no_lp']\n",
    "df_results['is_joke'] = df_results['condition'] == \"J\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26e9bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"data/processed/llm_classification.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508737a",
   "metadata": {},
   "source": [
    "## Pt. 2: Joke appreciation\n",
    "\n",
    "Response options:\n",
    "- Not Funny\n",
    "- Somewhat Funny\n",
    "- Moderately Funny\n",
    "- Funny\n",
    "- Very Funny\n",
    "\n",
    "**TODO**: Scale of 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c7c2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be shown a series of statements. For each, your task is to indicate how funny you find the statement to be.  \n"
     ]
    }
   ],
   "source": [
    "INSTRUCTIONS_APPRECIATION = \"You will be shown a series of statements. For each, your task is to indicate how funny you find the statement to be.  \"\n",
    "print(INSTRUCTIONS_APPRECIATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5aa7d",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "708b3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f06a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sentence, prompt, response):\n",
    "    prompt = \"{p}\\n\\nOn a scale of 1 to 5, how funny do you think this statement is? The scale is 1 (Not Funny), 2 (Somewhat Funny), 3 (Moderately Funny), 4 (Funny), and Very Funny (5).\\n\\n{x}\\n\\nAnswer: {y}\".format(\n",
    "        p = prompt, x = sentence, y = response)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfbdb71",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ff9e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"text-davinci-002\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d96ff607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [07:14<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    \n",
    "    sentence = row['Sentence']\n",
    "    answer = row['Answer']\n",
    "    \n",
    "    responses = {}\n",
    "    for r in range(1, 6):\n",
    "        responses[r] = format_prompt(sentence, prompt = INSTRUCTIONS_APPRECIATION, \n",
    "                               response = r)\n",
    "    \n",
    "    for model in models:\n",
    "\n",
    "        ## Get responses\n",
    "        r_to_lp = {}\n",
    "        for r, prompt in responses.items():\n",
    "            gpt_response = get_response(prompt, model = model)\n",
    "            token = gpt_response.to_dict()['choices'][0]['logprobs']['tokens'][-1]\n",
    "            if token.strip() != str(r):\n",
    "                print(token)\n",
    "                print(r)\n",
    "            lp_token = gpt_response.to_dict()['choices'][0]['logprobs']['token_logprobs'][-1]\n",
    "            r_to_lp[r] = lp_token\n",
    "            \n",
    "        max_key = max(r_to_lp, key=r_to_lp.get)\n",
    "        max_value = r_to_lp[max_key]\n",
    "        \n",
    "        probabilities = [math.exp(value) for value in r_to_lp.values()]\n",
    "        \n",
    "        entropy = -sum([p * math.log(p) for p in probabilities])\n",
    "\n",
    "        \n",
    "        ### TODO:\n",
    "        #### Get best-p response\n",
    "        #### Get p of best-p response\n",
    "        #### Get entropy of distribution\n",
    "        \n",
    "        results.append({\n",
    "            'model': model,\n",
    "            'sentence': sentence,\n",
    "            'answer': answer,\n",
    "            'condition': row['Condition'],\n",
    "            'best_response': max_key,\n",
    "            'best_response_lp': max_value,\n",
    "            'entropy': entropy\n",
    "        })\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38dd735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0eccf296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sentence</th>\n",
       "      <th>answer</th>\n",
       "      <th>condition</th>\n",
       "      <th>best_response</th>\n",
       "      <th>best_response_lp</th>\n",
       "      <th>entropy</th>\n",
       "      <th>is_joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A committee keeps minutes and takes hours.</td>\n",
       "      <td>Committees are very efficient.</td>\n",
       "      <td>J</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.615764</td>\n",
       "      <td>0.694764</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A committee keeps minutes and takes votes.</td>\n",
       "      <td>Committees keep records and make decisions.</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.649445</td>\n",
       "      <td>0.669604</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A device for finding furniture in the dark is ...</td>\n",
       "      <td>The candle gives off light.</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.613520</td>\n",
       "      <td>0.640976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A device for finding furniture in the dark is ...</td>\n",
       "      <td>People run into furniture when it's dark.</td>\n",
       "      <td>J</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.393362</td>\n",
       "      <td>0.704891</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>A good source of vitamin A is orange vegetable...</td>\n",
       "      <td>Carrots contain vitamin A.</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100589</td>\n",
       "      <td>0.098394</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model                                           sentence  \\\n",
       "0  text-davinci-002         A committee keeps minutes and takes hours.   \n",
       "1  text-davinci-002         A committee keeps minutes and takes votes.   \n",
       "2  text-davinci-002  A device for finding furniture in the dark is ...   \n",
       "3  text-davinci-002  A device for finding furniture in the dark is ...   \n",
       "4  text-davinci-002  A good source of vitamin A is orange vegetable...   \n",
       "\n",
       "                                        answer condition  best_response  \\\n",
       "0               Committees are very efficient.         J              3   \n",
       "1  Committees keep records and make decisions.         S              1   \n",
       "2                  The candle gives off light.         S              3   \n",
       "3    People run into furniture when it's dark.         J              3   \n",
       "4                   Carrots contain vitamin A.         E              1   \n",
       "\n",
       "   best_response_lp   entropy  is_joke  \n",
       "0         -0.615764  0.694764     True  \n",
       "1         -0.649445  0.669604    False  \n",
       "2         -0.613520  0.640976    False  \n",
       "3         -0.393362  0.704891     True  \n",
       "4         -0.100589  0.098394    False  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['is_joke'] = df_results['condition'] == \"J\"\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "255f1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"data/processed/llm_appreciation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "856269d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Charged with statutory rape, he told the judge he didn't know she was a statue.\",\n",
       "       'To get something done, a committee should consist of no more than three people, two of whom are dead.',\n",
       "       'The new tax forms are more realistic-- where your wife signs, it says: accomplice.',\n",
       "       'A committee keeps minutes and takes hours.',\n",
       "       'She told him he looked like a million, and she meant every syllable.',\n",
       "       'Some husbands are good providers, but only if you count children.',\n",
       "       'Some babies are born to rule, while others are weak.',\n",
       "       'Some babies are born to rule, while others are male.',\n",
       "       \"She's happy because she finally has a boyfriend who gets along with her fiance.\",\n",
       "       'She went on a fourteen day diet, but she only lost two weeks.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(\"best_response\", ascending = False)[['sentence', 'best_response', 'is_joke']].head(10)['sentence'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
